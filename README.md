# TheNewsCron ğŸ“°

**TheNewsCron** is an AI-powered news aggregation and publishing system designed for X (formerly Twitter).
It fetches fresh articles from external sources, evaluates their potential for engagement, and automatically generates X threads.

---

## ğŸš€ Features

- **News Aggregation** â†’ Pulls in the latest articles from multiple news APIs.
- **Article Scoring** â†’ Uses Gemini AI to assign a â€œvirality scoreâ€ to articles.
- **Thread Generation** â†’ Converts long-form articles into concise, engaging X threads.
- **Embeddings & Vector Store** â†’ Uses FAISS for semantic storage & retrieval.
- **Streamlit Dashboard** â†’ Monitor and manage the pipeline with a simple UI.
- **Modular Design** â†’ Independent modules for sources, scoring, embeddings, and storage.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ app.py                 # Streamlit dashboard
â”œâ”€â”€ aggregator.py          # Collects and stores new articles
â”œâ”€â”€ executor.py            # Scores articles and generates threads
â”œâ”€â”€ run_aggregator.sh      # Cron/script runner for aggregator
â”œâ”€â”€ run_executor.sh        # Cron/script runner for executor
â”‚
â”œâ”€â”€ embedder/              # Embedding logic
â”‚   â”œâ”€â”€ base.py
â”‚   â””â”€â”€ gemini.py
â”‚
â”œâ”€â”€ articlescorer/         # AI-based scoring logic
â”‚   â”œâ”€â”€ base.py
â”‚   â””â”€â”€ gemini.py
â”‚
â”œâ”€â”€ newssource/            # News fetchers
â”‚   â”œâ”€â”€ base.py
â”‚   â””â”€â”€ newsdataio.py
â”‚
â”œâ”€â”€ vectorstore/           # Vector storage abstraction (FAISS)
â”‚   â”œâ”€â”€ base.py
â”‚   â””â”€â”€ faiss.py
â”‚
â”œâ”€â”€ faiss_store            # FAISS index files
â”œâ”€â”€ articles.csv           # Stored articles
â”œâ”€â”€ threads.csv            # Generated threads
â”œâ”€â”€ state.json             # Processing state (checkpoints)
â”‚
â”œâ”€â”€ config.py              # Project config
â”œâ”€â”€ globals.py             # Shared constants
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ .env                   # API keys and environment variables
```

---

## âš™ï¸ Setup

### 1. Clone & Install

```bash
git clone https://github.com/your-username/thenewscron.git
cd thenewscron
pip install -r requirements.txt
```

### 2. Environment Variables

Create a `.env` file with required keys:

```ini
NEWSDATAIO_API_KEYS=your_news_api_key
GEMINI_API_KEYS=your_gemini_key
X_API_KEY=your_x_api_key
X_API_KEY_SECRET=your_x_api_key_secret
X_ACCESS_TOKEN=your_x_access_token
X_ACCESS_TOKEN_SECRET=your_x_access_token_secret
```

### 3. Data Storage

- **Articles** are stored in `articles.csv`
- **Threads** are stored in `threads.csv`
- **Embeddings** in `faiss_store`

---

## â–¶ï¸ Usage

### Run Aggregator (fetches articles)

```bash
python aggregator.py
```

### Run Executor (scores & generates threads)

```bash
python executor.py
```

### Streamlit Dashboard

```bash
streamlit run app.py
```

---

## ğŸ”„ Automation

You can automate runs via **cron jobs**:

```bash
# Example: run every hour
0 * * * * /path/to/run_aggregator.sh
30 * * * * /path/to/run_executor.sh
```

---

## ğŸ§© Modules

- **`newssource/`** â†’ Defines sources (e.g., NewsData.io)
- **`articlescorer/`** â†’ AI models for scoring
- **`embedder/`** â†’ Creates embeddings with Gemini
- **`vectorstore/`** â†’ Manages FAISS index

Each module follows a `base.py` abstract structure for easy extensibility.

---

## ğŸ› ï¸ Future Improvements

- Multi-source aggregation (RSS, GDELT, custom scrapers)
- Better scoring with fine-tuned models
- X API integration for **direct posting**
- Rich Streamlit dashboard (analytics, leaderboards)

---

## ğŸ“œ License

MIT License â€“ feel free to use and modify.
